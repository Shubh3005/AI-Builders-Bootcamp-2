{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from googleapiclient.discovery import build\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for Tesla company overview...\n",
      "Searching for Tesla Core values...\n",
      "Searching for Tesla mission and values...\n",
      "Searching for Tesla leadership team...\n",
      "Searching for Tesla revenue financials...\n",
      "Searching for Tesla company culture...\n",
      "Searching for Tesla latest news...\n",
      "Search results saved to Tesla_search_results.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "def google_search(query, api_key, cse_id, num_results=10):\n",
    "    service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
    "    res = service.cse().list(q=query, cx=cse_id, num=num_results).execute()\n",
    "    return res['items']\n",
    "\n",
    "# Example search query for company research\n",
    "def get_company_info(company_name, api_key, cse_id):\n",
    "    queries = {\n",
    "        'overview': f\"{company_name} company overview\",\n",
    "        'products_services': f\"{company_name} Core values\",\n",
    "        'mission_values': f\"{company_name} mission and values\",\n",
    "        'leadership': f\"{company_name} leadership team\",\n",
    "        'financial': f\"{company_name} revenue financials\",\n",
    "        'culture': f\"{company_name} company culture\",\n",
    "        'news': f\"{company_name} latest news\"\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for key, query in queries.items():\n",
    "        print(f\"Searching for {query}...\")\n",
    "        search_results = google_search(query, api_key, cse_id)\n",
    "        results[key] = search_results\n",
    "\n",
    "    return results\n",
    "\n",
    "# Write the search results to a CSV file\n",
    "def write_to_csv(company_data, company_name):\n",
    "    with open(f\"{company_name}_search_results.csv\", mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Category\", \"Title\", \"Link\"])\n",
    "\n",
    "        for category, results in company_data.items():\n",
    "            for result in results:\n",
    "                title = result.get('title', 'No title')\n",
    "                link = result.get('link', 'No link')\n",
    "                writer.writerow([category, title, link])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace these with your API key and CSE ID from Google\n",
    "    API_KEY = \"AIzaSyBRmdsbuKKgzs30mcimTO3pE_MLhbZgzoI\"\n",
    "    CSE_ID = \"e0b4e040586d4475e\"\n",
    "  \n",
    "    company_data = get_company_info(company_name, API_KEY, CSE_ID)\n",
    "\n",
    "    write_to_csv(company_data, company_name)\n",
    "\n",
    "    print(f\"Search results saved to {company_name}_search_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.28.1)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Requirement already satisfied: trio~=0.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from selenium) (0.28.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from selenium) (2024.12.14)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (25.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.tesla.com/about for category: overview\n",
      "Scraping https://www.forbes.com/companies/tesla/ for category: overview\n",
      "Scraping https://finance.yahoo.com/quote/TSLA/profile/ for category: overview\n",
      "Scraping https://www.linkedin.com/pulse/overview-history-tesla-inc-ashley-lobo for category: overview\n",
      "Scraping https://www.globaldata.com/company-profile/tesla-inc/ for category: overview\n",
      "Scraping https://ir.tesla.com/ for category: overview\n",
      "Scraping https://en.wikipedia.org/wiki/Tesla,_Inc. for category: overview\n",
      "Scraping https://ir.tesla.com/_flysystem/s3/sec/000162828024002390/tsla-20231231-gen.pdf for category: overview\n",
      "Scraping https://www.opensecrets.org/orgs/tesla-inc/summary?id=D000057516 for category: overview\n",
      "Scraping https://ir.tesla.com/sec-filings for category: overview\n",
      "Scraping https://www.tesla.com/about for category: products_services\n",
      "Scraping https://www.edrawmind.com/article/tesla-mission-and-vision-statement-analysis.html for category: products_services\n",
      "Scraping https://businessmodelanalyst.com/tesla-mission-and-vision-statement/ for category: products_services\n",
      "Scraping https://www.designgurus.io/answers/detail/what-are-teslas-values for category: products_services\n",
      "Scraping https://www.linkedin.com/pulse/elon-musk-tesla-importance-brand-authenticity-consistency-sightly for category: products_services\n",
      "Scraping https://benny0522.medium.com/lets-know-more-about-tesla-its-core-value-brand-personality-mission-and-vision-dc2f2a600a8b for category: products_services\n",
      "Scraping https://www.linkedin.com/pulse/dissent-debate-pushback-my-tesla-valuation-aswath-damodaran for category: products_services\n",
      "Scraping https://boardmix.com/analysis/tesla-mission-and-vision-statement-analysis/ for category: products_services\n",
      "Scraping https://www.electro-tech-online.com/threads/choosing-capacitor-value-for-my-tesla-coil.155932/ for category: products_services\n",
      "Scraping https://www.yesenergy.com/tesla-energy-forecasting-solutions for category: products_services\n",
      "Scraping https://www.tesla.com/about for category: mission_values\n",
      "Scraping https://businessmodelanalyst.com/tesla-mission-and-vision-statement/ for category: mission_values\n",
      "Scraping https://www.tesla.com/blog for category: mission_values\n",
      "Scraping https://aluminium-stewardship.org/about-asi/members/Tesla-Inc- for category: mission_values\n",
      "Scraping https://www.tesla.com/impact for category: mission_values\n",
      "Scraping https://panmore.com/tesla-motors-inc-vision-statement-mission-statement-analysis for category: mission_values\n",
      "Scraping https://www.edrawmind.com/article/tesla-mission-and-vision-statement-analysis.html for category: mission_values\n",
      "Scraping https://boardmix.com/analysis/tesla-mission-and-vision-statement-analysis/ for category: mission_values\n",
      "Scraping https://www.reddit.com/r/teslainvestorsclub/comments/k8vr8x/tesla_isnt_a_car_company_mission_statement_to/ for category: mission_values\n",
      "Scraping https://bstrategyhub.com/tesla-mission-statement-operational-goals-a-culture/ for category: mission_values\n",
      "Scraping https://ir.tesla.com/corporate for category: leadership\n",
      "Scraping https://www.linkedin.com/posts/julianibarz_our-teslabot-team-at-tesla-is-hiring-across-activity-7007159937374048256-pRuq for category: leadership\n",
      "Scraping https://www.tesla.com/careers/search/job/store-manager-cork-229786 for category: leadership\n",
      "Scraping https://www.linkedin.com/in/roshant for category: leadership\n",
      "Scraping https://www.tesla.com/careers/search/job/supply-chain-program-manager-energy-225621 for category: leadership\n",
      "Scraping https://www.investopedia.com/articles/company-insights/090316/who-driving-teslas-management-team-tsla.asp for category: leadership\n",
      "Scraping https://www.tesla.com/careers/search/job/corporate-finance-analyst--232698 for category: leadership\n",
      "Scraping https://joshbersin.com/2018/06/my-day-at-telsa-what-i-learned/ for category: leadership\n",
      "Scraping https://www.tesla.com/careers/search/job/facilities-manager-m-w-d-central-europe-229411 for category: leadership\n",
      "Scraping https://www.uhcl.edu/about/strategic-plan/tesla-internship-cleaner-energy-aligns-with-my-values-says-uhcl-student for category: leadership\n",
      "Scraping https://ir.tesla.com/ for category: financial\n",
      "Scraping https://www.reddit.com/r/dataisbeautiful/comments/10lo5mj/oc_teslas_income_statement_for_the_year_2022_they/ for category: financial\n",
      "Scraping https://ir.tesla.com/_flysystem/s3/sec/000162828024002390/tsla-20231231-gen.pdf for category: financial\n",
      "Scraping https://www.reddit.com/r/dataisbeautiful/comments/1cbt92o/oc_behind_teslas_billion_profit_latest_earnings/ for category: financial\n",
      "Scraping https://ir.tesla.com/sec-filings for category: financial\n",
      "Scraping https://www.nasdaq.com/market-activity/stocks/tsla/earnings for category: financial\n",
      "Error scraping https://www.nasdaq.com/market-activity/stocks/tsla/earnings: Message: javascript error: Cannot read properties of undefined (reading 'toUpperCase')\n",
      "  (Session info: chrome=131.0.6778.265)\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x000000010305a138 cxxbridge1$str$ptr + 3653888\n",
      "1   chromedriver                        0x0000000103052988 cxxbridge1$str$ptr + 3623248\n",
      "2   chromedriver                        0x0000000102ab8968 cxxbridge1$string$len + 89228\n",
      "3   chromedriver                        0x0000000102abd84c cxxbridge1$string$len + 109424\n",
      "4   chromedriver                        0x0000000102abf89c cxxbridge1$string$len + 117696\n",
      "5   chromedriver                        0x0000000102abf944 cxxbridge1$string$len + 117864\n",
      "6   chromedriver                        0x0000000102af7f10 cxxbridge1$string$len + 348724\n",
      "7   chromedriver                        0x0000000102af2ec4 cxxbridge1$string$len + 328168\n",
      "8   chromedriver                        0x0000000102b364f0 cxxbridge1$string$len + 604180\n",
      "9   chromedriver                        0x0000000102af1564 cxxbridge1$string$len + 321672\n",
      "10  chromedriver                        0x0000000102af21b4 cxxbridge1$string$len + 324824\n",
      "11  chromedriver                        0x0000000103024fc0 cxxbridge1$str$ptr + 3436424\n",
      "12  chromedriver                        0x00000001030282dc cxxbridge1$str$ptr + 3449508\n",
      "13  chromedriver                        0x000000010300be60 cxxbridge1$str$ptr + 3333672\n",
      "14  chromedriver                        0x0000000103028b9c cxxbridge1$str$ptr + 3451748\n",
      "15  chromedriver                        0x0000000102ffd678 cxxbridge1$str$ptr + 3274304\n",
      "16  chromedriver                        0x00000001030432b4 cxxbridge1$str$ptr + 3560060\n",
      "17  chromedriver                        0x0000000103043430 cxxbridge1$str$ptr + 3560440\n",
      "18  chromedriver                        0x00000001030525fc cxxbridge1$str$ptr + 3622340\n",
      "19  libsystem_pthread.dylib             0x00000001954e32e4 _pthread_start + 136\n",
      "20  libsystem_pthread.dylib             0x00000001954de0fc thread_start + 8\n",
      "\n",
      "Scraping https://www.wsj.com/market-data/quotes/TSLA/financials/annual/income-statement for category: financial\n",
      "Scraping https://livestream.tesla.com/ for category: financial\n",
      "Scraping https://www.linkedin.com/pulse/tesla-vs-toyota-brian-hatano-5nllc for category: financial\n",
      "Scraping https://finance.yahoo.com/quote/TSLA/financials/ for category: financial\n",
      "Scraping https://www.tesla.com/impact for category: culture\n",
      "Scraping https://www.linkedin.com/pulse/tesla-case-study-complete-assessment-culture-teams-bianca for category: culture\n",
      "Scraping https://panmore.com/tesla-motors-inc-organizational-culture-characteristics-analysis for category: culture\n",
      "Scraping https://www.culturemonkey.io/employee-engagement/tesla-company-culture/ for category: culture\n",
      "Scraping https://www.emexmag.com/teslas-company-culture-a-catalyst-for-innovation-and-global-success/ for category: culture\n",
      "Scraping https://www.thenation.com/article/society/tesla-racism-sexual-harassment/ for category: culture\n",
      "Scraping https://sloanreview.mit.edu/culture500/company/c560/Tesla for category: culture\n",
      "Scraping https://www.glassdoor.com/Reviews/Tesla-company-culture-Reviews-EI_IE43129.0,5_KH6,21.htm for category: culture\n",
      "Scraping https://www.braineet.com/blog/tesla-innovation-culture for category: culture\n",
      "Scraping https://www.reddit.com/r/SelfDrivingCars/comments/o2etq1/some_insight_on_teslas_work_culture/ for category: culture\n",
      "Scraping https://www.tesla.com/blog for category: news\n",
      "Scraping https://www.cnbc.com/quotes/TSLA for category: news\n",
      "Scraping https://www.notateslaapp.com/ for category: news\n",
      "Scraping https://www.teslarati.com/latest-tesla-news/ for category: news\n",
      "Scraping https://www.notateslaapp.com/software-updates/ for category: news\n",
      "Scraping https://ir.tesla.com/ for category: news\n",
      "Scraping https://www.cbsnews.com/tag/tesla/ for category: news\n",
      "Scraping https://ir.tesla.com/press for category: news\n",
      "Scraping https://finance.yahoo.com/quote/TSLA/news/ for category: news\n",
      "Scraping https://www.reddit.com/r/TeslaLounge/comments/1d1fgp0/why_you_may_still_be_on_tesla_update_202489_or/ for category: news\n",
      "Scraped data saved to scraped_data.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Set up the WebDriver (Ensure that you have ChromeDriver or GeckoDriver installed)\n",
    "def setup_driver():\n",
    "    # Initialize the Chrome WebDriver (adjust for your browser if needed)\n",
    "    driver = webdriver.Chrome()  # Add path to your ChromeDriver if necessary\n",
    "    return driver\n",
    "\n",
    "# Function to scrape the data from each website\n",
    "def scrape_website(driver, url, category):\n",
    "    driver.get(url)\n",
    "    time.sleep(2)  # Give the website some time to load\n",
    "    \n",
    "    # Dictionary to store the scraped data\n",
    "    scraped_data = {\n",
    "        'Category': category,\n",
    "        'URL': url,\n",
    "        'Content': ''\n",
    "    }\n",
    "\n",
    "    # Example: Scrape the entire text from the body of the webpage\n",
    "    try:\n",
    "        body_content = driver.find_element(By.TAG_NAME, 'body').text\n",
    "        scraped_data['Content'] = body_content\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "    \n",
    "    return scraped_data\n",
    "\n",
    "# Function to process the CSV file and extract data\n",
    "def process_csv_and_scrape(csv_file):\n",
    "    # Load CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Set up the WebDriver\n",
    "    driver = setup_driver()\n",
    "    \n",
    "    # List to hold all scraped data\n",
    "    all_scraped_data = []\n",
    "    \n",
    "    # Iterate through each row in the CSV\n",
    "    for index, row in df.iterrows():\n",
    "        category = row['Category']\n",
    "        url = row['Link']\n",
    "        print(f\"Scraping {url} for category: {category}\")\n",
    "        \n",
    "        # Scrape the website data\n",
    "        scraped_data = scrape_website(driver, url, category)\n",
    "        all_scraped_data.append(scraped_data)\n",
    "    \n",
    "    # Close the WebDriver when done\n",
    "    driver.quit()\n",
    "    \n",
    "    # Return the scraped data\n",
    "    return all_scraped_data\n",
    "\n",
    "# Save scraped data to a new CSV file\n",
    "def save_to_csv(scraped_data, output_file):\n",
    "    keys = scraped_data[0].keys()  # Get the column names from the first scraped data entry\n",
    "    with open(output_file, 'w', newline='') as output_csv:\n",
    "        dict_writer = csv.DictWriter(output_csv, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(scraped_data)\n",
    "    print(f\"Scraped data saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the input CSV file and the output file for scraped data\n",
    "    input_csv_file = 'tesla_search_results.csv'  # Replace with your CSV file name\n",
    "    output_csv_file = 'scraped_data.csv'\n",
    "    \n",
    "    # Process the CSV file and scrape data\n",
    "    scraped_data = process_csv_and_scrape(input_csv_file)\n",
    "    \n",
    "    # Save the scraped data to a new CSV file\n",
    "    save_to_csv(scraped_data, output_csv_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
